# -*- coding: utf-8 -*-
"""MachineLearningHw4.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wcs3fHfFud2nomYf32sVNIPeU2Jb4MWW

# DBSCAN
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

noisy_img = np.loadtxt("/content/noisy_mnist.txt")

plt.imshow(noisy_img, cmap='gray')
plt.axis('off')

n = 28
Y,X = np.meshgrid(np.arange(28), np.arange(28))

dat = np.stack((Y.ravel(),
                X.ravel(),
                noisy_img.ravel()), axis= 1)

dat.shape
dat[:10]

from sklearn.cluster import DBSCAN
dbscan = DBSCAN(eps = 1.5 , min_samples=3)
dbscan.fit(dat)


labels_img = dbscan.labels_.reshape(28,28)
plt.imshow(labels_img)
plt.colorbar()

# Helper function to be used with HW-4 of DSC345/540 (Winter 2025)

def replace_intensity(img, i, j, width):
    '''Replace intensity of the (i,j)-th pixel with the majority intensity
    of a patch of specific width around it'''

    # size of the image
    n,m = img.shape

    # creating a bounding box as the neighborhodd of the pixel
    w = int((width-1)/2)
    i_lb = max(i-w, 0)
    i_ub = min(i+w, n)
    j_lb = max(j-w, 0)
    j_ub = min(j+w, m)
    patch = img[i_lb:i_ub, j_lb:j_ub].ravel()

    # only consider clean pixels in the neighborhood
    patch = patch[patch!=-1]

    # if there exists at least one clean pixel,
    # run the majority voting
    if len(patch)>0:
        vals,cnts = np.unique(patch, return_counts=True)
        return vals[np.argmax(cnts)]
    else:
        # if no clean pixel in the patch,
        # just return the current intensity
        return img[i,j]




width = 5 # width of neighboring patch

# copying the current labels to a different variable
cleaned_labels_img = labels_img.copy()
for i in range(n):
  for j in range(n):
    if labels_img[i,j] == -1:
      cleaned_labels_img[i,j] = replace_intensity(
          labels_img,
          i,
          j,
          width
      )

plt.figure(figsize=(4, 4))
plt.imshow(cleaned_labels_img, cmap='gray')
plt.axis('off')
plt.title("Denoised MNIST Image (After DBSCAN + Intensity Replacement)")
plt.show()

"""# Bayesian Network"""

import pandas as pd
dat = pd.read_csv("/content/heart_disease.csv")
dat

from sklearn.model_selection import train_test_split
randstate = 123
train_df, test_df = train_test_split(dat,test_size=0.2, random_state=randstate)

!pip install -q pgmpy

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import KBinsDiscretizer

from pgmpy.models import DiscreteBayesianNetwork
from pgmpy.estimators import MaximumLikelihoodEstimator
from pgmpy.inference import VariableElimination

# Create the model using the new class name
model = DiscreteBayesianNetwork([
    ('Age', 'Chol'),
    ('Sex', 'Chol'),
    ('Chol', 'HD'),
    ('RestBP', 'HD'),
    ('FastingBS', 'HD')
])
# Nodes and edges
print("Nodes:", list(model.nodes()))
print("Edges:", list(model.edges()))


# First 5 (conditional) independencies
inds = model.get_independencies()
first5 = "\n".join(str(inds).split("\n")[:5])
print("\nFirst 5 independencies:\n", first5)

from pgmpy.estimators import MaximumLikelihoodEstimator
model.fit(train_df, estimator=MaximumLikelihoodEstimator)
for cpd in model.get_cpds():
    print(cpd)

from pgmpy.inference import VariableElimination
inference = VariableElimination(model)

q_female_35 = inference.query(variables=['HD'], evidence={'Age': 35, 'Sex': 0})
q_male_35   = inference.query(variables=['HD'], evidence={'Age': 35, 'Sex': 1})

print("Female, Age=35:\n", q_female_35)
print("Male,   Age=35:\n", q_male_35)



q1 = inference.query(variables=['HD'], evidence={'Chol': 172, 'Age': 35, 'Sex': 0})
q2 = inference.query(variables=['HD'], evidence={'Chol': 172, 'Age': 35, 'Sex': 1})
q3 = inference.query(variables=['HD'], evidence={'Chol': 172, 'Age': 60, 'Sex': 1})

print("A=35,S=0,Chol=172:\n", q1)
print("A=35,S=1,Chol=172:\n", q2)
print("A=60,S=1,Chol=172:\n", q3)

import numpy as np
from pgmpy.inference import VariableElimination
from sklearn.metrics import accuracy_score

# Make sure your trained model is 'model' and your test set is 'test_df'
# Columns assumed: ['Age','Sex','RestBP','Chol','FastingBS','HD']

inference = VariableElimination(model)

def predict_heart_disease(row):
    """Make BN inference for a single test row (HD is the last column)."""
    # Use all predictors as evidence (exclude the target HD)
    evidence = row.drop(labels=['HD']).to_dict()
    result = inference.map_query(variables=['HD'], evidence=evidence, show_progress=False)
    return int(result['HD'])

# Predict for each row
preds = np.zeros(len(test_df), dtype=int)
for i in range(len(test_df)):
    preds[i] = predict_heart_disease(test_df.iloc[i, :])

# Compute accuracy (either way works)
acc1 = (preds == test_df['HD'].to_numpy()).mean()
acc2 = accuracy_score(test_df['HD'].to_numpy(), preds)

print(f"BN accuracy (manual): {acc1:.4f}")
print(f"BN accuracy (sklearn): {acc2:.4f}")